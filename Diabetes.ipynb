{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOxF7cz7ZwGvaEzpUF/rEAo",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/TejasKawle/Diabetes-Detection-System/blob/main/Diabetes.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j0fdInwoZSc-",
        "outputId": "e2136329-4ae2-4861-86ab-d0dc045c59d4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Dataset Loaded Successfully!\n",
            "\n",
            "Dataset Shape: (768, 9)\n",
            "\n",
            "Statistical Summary:\n",
            "        Pregnancies     Glucose  BloodPressure  ...  DiabetesPedigreeFunction         Age     Outcome\n",
            "count   768.000000  768.000000     768.000000  ...                768.000000  768.000000  768.000000\n",
            "mean      3.845052  120.894531      69.105469  ...                  0.471876   33.240885    0.348958\n",
            "std       3.369578   31.972618      19.355807  ...                  0.331329   11.760232    0.476951\n",
            "min       0.000000    0.000000       0.000000  ...                  0.078000   21.000000    0.000000\n",
            "25%       1.000000   99.000000      62.000000  ...                  0.243750   24.000000    0.000000\n",
            "50%       3.000000  117.000000      72.000000  ...                  0.372500   29.000000    0.000000\n",
            "75%       6.000000  140.250000      80.000000  ...                  0.626250   41.000000    1.000000\n",
            "max      17.000000  199.000000     122.000000  ...                  2.420000   81.000000    1.000000\n",
            "\n",
            "[8 rows x 9 columns]\n",
            "\n",
            "Class Distribution:\n",
            " Outcome\n",
            "0    500\n",
            "1    268\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Training Data Accuracy: 78.66%\n",
            "Testing Data Accuracy: 77.27%\n",
            "\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.78      0.91      0.84       100\n",
            "           1       0.76      0.52      0.62        54\n",
            "\n",
            "    accuracy                           0.77       154\n",
            "   macro avg       0.77      0.71      0.73       154\n",
            "weighted avg       0.77      0.77      0.76       154\n",
            "\n",
            "\n",
            "Confusion Matrix:\n",
            " [[91  9]\n",
            " [26 28]]\n",
            "\n",
            "Model saved to diabetes_model.pkl\n",
            "Scaler saved to diabetes_scaler.pkl\n",
            "\n",
            "Prediction for input data: Non-Diabetic\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/base.py:493: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "# Importing the dependencies\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.model_selection import train_test_split, cross_val_score\n",
        "from sklearn import svm\n",
        "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
        "import joblib\n",
        "\n",
        "# Function to load and explore the dataset\n",
        "def load_and_explore_data(file_path):\n",
        "    try:\n",
        "        data = pd.read_csv(file_path)\n",
        "        print(\"\\nDataset Loaded Successfully!\")\n",
        "        print(f\"\\nDataset Shape: {data.shape}\")\n",
        "        print(\"\\nStatistical Summary:\\n\", data.describe())\n",
        "        print(\"\\nClass Distribution:\\n\", data['Outcome'].value_counts())\n",
        "        return data\n",
        "    except FileNotFoundError:\n",
        "        print(\"Error: File not found. Please check the file path.\")\n",
        "        return None\n",
        "\n",
        "# Function to preprocess the data\n",
        "def preprocess_data(data):\n",
        "    X = data.drop(columns='Outcome', axis=1)\n",
        "    Y = data['Outcome']\n",
        "    scaler = StandardScaler()\n",
        "    scaler.fit(X)\n",
        "    X = scaler.transform(X)\n",
        "    return X, Y, scaler\n",
        "\n",
        "# Function to train the model\n",
        "def train_model(X_train, Y_train):\n",
        "    classifier = svm.SVC(kernel='linear')\n",
        "    classifier.fit(X_train, Y_train)\n",
        "    return classifier\n",
        "\n",
        "# Function to evaluate the model\n",
        "def evaluate_model(classifier, X_train, Y_train, X_test, Y_test):\n",
        "    # Accuracy on training data\n",
        "    train_pred = classifier.predict(X_train)\n",
        "    train_accuracy = accuracy_score(Y_train, train_pred)\n",
        "\n",
        "    # Accuracy on testing data\n",
        "    test_pred = classifier.predict(X_test)\n",
        "    test_accuracy = accuracy_score(Y_test, test_pred)\n",
        "\n",
        "    print(\"\\nTraining Data Accuracy: {:.2f}%\".format(train_accuracy * 100))\n",
        "    print(\"Testing Data Accuracy: {:.2f}%\".format(test_accuracy * 100))\n",
        "\n",
        "    # Classification report and confusion matrix\n",
        "    print(\"\\nClassification Report:\\n\", classification_report(Y_test, test_pred))\n",
        "    print(\"\\nConfusion Matrix:\\n\", confusion_matrix(Y_test, test_pred))\n",
        "\n",
        "# Function to save the model and scaler\n",
        "def save_model(classifier, scaler, model_path, scaler_path):\n",
        "    joblib.dump(classifier, model_path)\n",
        "    joblib.dump(scaler, scaler_path)\n",
        "    print(f\"\\nModel saved to {model_path}\")\n",
        "    print(f\"Scaler saved to {scaler_path}\")\n",
        "\n",
        "# Function for prediction\n",
        "def make_prediction(input_data, classifier, scaler):\n",
        "    try:\n",
        "        input_array = np.asarray(input_data)\n",
        "        input_reshaped = input_array.reshape(1, -1)\n",
        "        std_data = scaler.transform(input_reshaped)\n",
        "        prediction = classifier.predict(std_data)\n",
        "        return \"Diabetic\" if prediction[0] == 1 else \"Non-Diabetic\"\n",
        "    except Exception as e:\n",
        "        return f\"Error in prediction: {e}\"\n",
        "\n",
        "# Main workflow\n",
        "def main():\n",
        "    # File path for the dataset\n",
        "    file_path = 'diabetes.csv'\n",
        "\n",
        "    # Load and explore data\n",
        "    data = load_and_explore_data(file_path)\n",
        "    if data is None:\n",
        "        return\n",
        "\n",
        "    # Data preprocessing\n",
        "    X, Y, scaler = preprocess_data(data)\n",
        "\n",
        "    # Splitting the data\n",
        "    X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, stratify=Y, random_state=2)\n",
        "\n",
        "    # Train the model\n",
        "    classifier = train_model(X_train, Y_train)\n",
        "\n",
        "    # Evaluate the model\n",
        "    evaluate_model(classifier, X_train, Y_train, X_test, Y_test)\n",
        "\n",
        "    # Save the model and scaler\n",
        "    save_model(classifier, scaler, 'diabetes_model.pkl', 'diabetes_scaler.pkl')\n",
        "\n",
        "    # Make a prediction\n",
        "    input_data = (0, 105, 64, 41, 142, 41.5, 0.173, 22)  # Example input\n",
        "    result = make_prediction(input_data, classifier, scaler)\n",
        "    print(f\"\\nPrediction for input data: {result}\")\n",
        "\n",
        "# Execute the main workflow\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ngFaqkeSbBls"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}